{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/TartuNLP/grammar-worker/blob/gec-and-spell/GEC_and_spell_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spell-checking and Grammatical Error Correction Demo\n",
    "\n",
    "Demo for using [https://koodivaramu.eesti.ee/tartunlp/corrector](https://koodivaramu.eesti.ee/tartunlp/corrector) that corrects Estonian text using spell-checking and grammatical error correction (GEC) models. "
   ],
   "metadata": {
    "id": "Jho_ZS1rtJwS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "Clone the repo, install dependencies and download models. It is advisable to create a Python 3.10 environment outside of Colab. "
   ],
   "metadata": {
    "id": "TfLyafy9tkvO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1yRSNzEd5OWl",
    "outputId": "d9793e50-6d61-4184-dbfb-a9a46d4de397"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'corrector'...\n",
      "remote: Enumerating objects: 273, done.\u001B[K\n",
      "remote: Counting objects: 100% (122/122), done.\u001B[K\n",
      "remote: Compressing objects: 100% (50/50), done.\u001B[K\n",
      "remote: Total 273 (delta 71), reused 122 (delta 71), pack-reused 151\u001B[K\n",
      "Receiving objects: 100% (273/273), 80.09 KiB | 911.00 KiB/s, done.\n",
      "Resolving deltas: 100% (137/137), done.\n",
      "/content/corrector/corrector\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/TartuNLP/fairseq.git@mtee-0.1.0 (from -r requirements.txt (line 7))\n",
      "  Cloning https://github.com/TartuNLP/fairseq.git (to revision mtee-0.1.0) to /tmp/pip-req-build-0hfe6cjf\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/TartuNLP/fairseq.git /tmp/pip-req-build-0hfe6cjf\n",
      "  Running command git checkout -q 1a6f364b8af6e746dd1fc623c8cf670a0be5b696\n",
      "  Resolved https://github.com/TartuNLP/fairseq.git to commit 1a6f364b8af6e746dd1fc623c8cf670a0be5b696\n",
      "  Running command git submodule update --init --recursive -q\n",
      "  From https://github.com/ngoyal2707/Megatron-LM\n",
      "   * branch            adb23324c222aad0aad89308e70302d996a5eaeb -> FETCH_HEAD\n",
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Installing backend dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting nltk~=3.7\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m45.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting torch==1.13.1\n",
      "  Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m887.4/887.4 MB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting torchvision==0.14.1\n",
      "  Downloading torchvision-0.14.1-cp39-cp39-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.2/24.2 MB\u001B[0m \u001B[31m47.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting torchaudio==0.13.1\n",
      "  Downloading torchaudio-0.13.1-cp39-cp39-manylinux1_x86_64.whl (4.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.2/4.2 MB\u001B[0m \u001B[31m69.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pyyaml==6.0\n",
      "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m661.8/661.8 KB\u001B[0m \u001B[31m46.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pika==1.3.1\n",
      "  Using cached pika-1.3.1-py3-none-any.whl (155 kB)\n",
      "Collecting sentencepiece==0.1.97\n",
      "  Using cached sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting pydantic~=1.10.5\n",
      "  Downloading pydantic-1.10.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.2/3.2 MB\u001B[0m \u001B[31m104.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting fastapi~=0.92.0\n",
      "  Using cached fastapi-0.92.0-py3-none-any.whl (56 kB)\n",
      "Collecting uvicorn~=0.20.0\n",
      "  Using cached uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
      "Collecting numpy<1.24.0\n",
      "  Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m17.1/17.1 MB\u001B[0m \u001B[31m87.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting swig~=3.0.2\n",
      "  Using cached swig-3.0.12-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.5 MB)\n",
      "Collecting jamspell~=0.0.12\n",
      "  Using cached jamspell-0.0.12.tar.gz (174 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting mosestokenizer~=1.2.1\n",
      "  Using cached mosestokenizer-1.2.1-py3-none-any.whl\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.0/21.0 MB\u001B[0m \u001B[31m19.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m849.3/849.3 KB\u001B[0m \u001B[31m65.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m557.1/557.1 MB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.13.1->-r requirements.txt (line 2)) (4.5.0)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m317.1/317.1 MB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1->-r requirements.txt (line 3)) (2.25.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.14.1->-r requirements.txt (line 3)) (8.4.0)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 2)) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 2)) (57.4.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (8.1.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (2022.6.2)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.9/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (2.3.1)\n",
      "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.9/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (1.0.7)\n",
      "Requirement already satisfied: cffi in /usr/local/lib/python3.9/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (1.15.1)\n",
      "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.9/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (2.0.6)\n",
      "Requirement already satisfied: bitarray in /usr/local/lib/python3.9/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (2.7.3)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (0.29.33)\n",
      "Requirement already satisfied: starlette<0.26.0,>=0.25.0 in /usr/local/lib/python3.9/dist-packages (from fastapi~=0.92.0->-r requirements.txt (line 10)) (0.25.0)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.9/dist-packages (from uvicorn~=0.20.0->-r requirements.txt (line 11)) (0.14.0)\n",
      "Requirement already satisfied: openfile in /usr/local/lib/python3.9/dist-packages (from mosestokenizer~=1.2.1->-r requirements.txt (line 15)) (0.0.7)\n",
      "Requirement already satisfied: docopt in /usr/local/lib/python3.9/dist-packages (from mosestokenizer~=1.2.1->-r requirements.txt (line 15)) (0.6.2)\n",
      "Requirement already satisfied: uctools in /usr/local/lib/python3.9/dist-packages (from mosestokenizer~=1.2.1->-r requirements.txt (line 15)) (1.3.0)\n",
      "Requirement already satisfied: toolwrapper in /usr/local/lib/python3.9/dist-packages (from mosestokenizer~=1.2.1->-r requirements.txt (line 15)) (2.1.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.9/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (4.8)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (2.7.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (4.9.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (0.8.10)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.9/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette<0.26.0,>=0.25.0->fastapi~=0.92.0->-r requirements.txt (line 10)) (3.6.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (2.21)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 3)) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 3)) (1.26.14)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 3)) (2022.12.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<0.26.0,>=0.25.0->fastapi~=0.92.0->-r requirements.txt (line 10)) (1.3.0)\n",
      "Building wheels for collected packages: jamspell\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\n",
      "  \n",
      "  \u001B[31m×\u001B[0m \u001B[32mpython setup.py bdist_wheel\u001B[0m did not run successfully.\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\n",
      "  \u001B[31m╰─>\u001B[0m See above for output.\n",
      "  \n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Building wheel for jamspell (setup.py) ... \u001B[?25lerror\n",
      "\u001B[31m  ERROR: Failed building wheel for jamspell\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[?25h  Running setup.py clean for jamspell\n",
      "Failed to build jamspell\n",
      "Installing collected packages: swig, sentencepiece, jamspell, uvicorn, pyyaml, pydantic, pika, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, nltk, mosestokenizer, nvidia-cudnn-cu11, torch, fastapi, torchvision, torchaudio\n",
      "  Running setup.py install for jamspell ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[33m  DEPRECATION: jamspell was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001B[0m\u001B[33m\n",
      "\u001B[0mSuccessfully installed fastapi-0.92.0 jamspell-0.0.12 mosestokenizer-1.2.1 nltk-3.8.1 numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pika-1.3.1 pydantic-1.10.6 pyyaml-6.0 sentencepiece-0.1.97 swig-3.0.12 torch-1.13.1 torchaudio-0.13.1 torchvision-0.14.1 uvicorn-0.20.0\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "! git clone https://koodivaramu.eesti.ee/tartunlp/corrector.git \n",
    "%cd corrector\n",
    "! pip install -r requirements.txt\n",
    "! python -c \"import nltk; nltk.download(\\\"punkt\\\")\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Az5q9Jz27U3L",
    "outputId": "077397a6-3b10-4a40-bc98-0ff8aa956070"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Updated git hooks.\n",
      "Git LFS initialized.\n",
      "Cloning into 'GEC-noisy-nmt-ut'...\n",
      "remote: Enumerating objects: 19, done.\u001B[K\n",
      "remote: Counting objects: 100% (19/19), done.\u001B[K\n",
      "remote: Compressing objects: 100% (18/18), done.\u001B[K\n",
      "remote: Total 19 (delta 5), reused 0 (delta 0), pack-reused 0\u001B[K\n",
      "Unpacking objects: 100% (19/19), 63.25 KiB | 7.03 MiB/s, done.\n",
      "Cloning into 'GEC-synthetic-pretrain-ut-ft'...\n",
      "remote: Enumerating objects: 21, done.\u001B[K\n",
      "remote: Counting objects: 100% (21/21), done.\u001B[K\n",
      "remote: Compressing objects: 100% (20/20), done.\u001B[K\n",
      "remote: Total 21 (delta 6), reused 0 (delta 0), pack-reused 0\u001B[K\n",
      "Unpacking objects: 100% (21/21), 63.46 KiB | 4.53 MiB/s, done.\n",
      "Filtering content: 100% (4/4), 828.89 MiB | 69.65 MiB/s, done.\n",
      "Cloning into 'etnc19_reference_corpus_model_6000000_lines'...\n",
      "remote: Enumerating objects: 12, done.\u001B[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001B[K\n",
      "remote: Compressing objects: 100% (10/10), done.\u001B[K\n",
      "remote: Total 12 (delta 2), reused 0 (delta 0), pack-reused 0\u001B[K\n",
      "Unpacking objects: 100% (12/12), 1.39 KiB | 475.00 KiB/s, done.\n",
      "Cloning into 'etnc19_web_2019'...\n",
      "remote: Enumerating objects: 6, done.\u001B[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001B[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001B[K\n",
      "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\u001B[K\n",
      "Unpacking objects: 100% (6/6), 815 bytes | 815.00 KiB/s, done.\n",
      "Cloning into 'etnc19_reference_corpus_6000000_web_2019_600000'...\n",
      "remote: Enumerating objects: 6, done.\u001B[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001B[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001B[K\n",
      "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0\u001B[K\n",
      "Unpacking objects: 100% (6/6), 855 bytes | 855.00 KiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "! git lfs install\n",
    "\n",
    "# GEC models\n",
    "\n",
    "! git clone https://huggingface.co/tartuNLP/GEC-noisy-nmt-ut models/tartuNLP/GEC-noisy-nmt-ut\n",
    "! git clone https://huggingface.co/tartuNLP/GEC-synthetic-pretrain-ut-ft models/tartuNLP/GEC-synthetic-pretrain-ut-ft\n",
    "\n",
    "# Spell models\n",
    "\n",
    "! git clone https://huggingface.co/Jaagup/etnc19_reference_corpus_model_6000000_lines models/Jaagup/etnc19_reference_corpus_model_6000000_lines\n",
    "! git clone https://huggingface.co/Jaagup/etnc19_web_2019 models/Jaagup/etnc19_web_2019\n",
    "! git clone https://huggingface.co/Jaagup/etnc19_reference_corpus_6000000_web_2019_600000 models/Jaagup/etnc19_reference_corpus_6000000_web_2019_600000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models in action\n",
    "It is possible to use only speller or only GEC model or both models."
   ],
   "metadata": {
    "id": "QbZGDGhWvElx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yYqG3Yi45jPd"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from dataclasses import asdict\n",
    "from gec_worker import GEC, read_gec_config\n",
    "from gec_worker import Speller, read_speller_config\n",
    "from gec_worker.dataclasses import Request\n",
    "from gec_worker import MultiCorrector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading the models\n"
   ],
   "metadata": {
    "id": "iPNFtRwDxonZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Two available GEC models are\n",
    "\n",
    "* `GEC-synthetic-pretrain-ut-ft` - > slightly higher precision & lower recall (preferred)\n",
    "* `GEC-noisy-nmt-ut` - > slightly higher recall & lower precision "
   ],
   "metadata": {
    "id": "WvcvXpiGvH2t"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cOEDlt7I6ceg"
   },
   "outputs": [],
   "source": [
    "# Let's first load the second model\n",
    "\n",
    "gec_config = read_gec_config('models/GEC-noisy-nmt-ut.yaml')\n",
    "gec = GEC(gec_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Three available spell-checking models are\n",
    "\n",
    "* `etnc19_reference_corpus_6000000` - > highest recall, lowest precision\n",
    "* `etnc19_web_2019` - > highest precision, lowest recall\n",
    "* `etnc19_reference_corpus_6000000_web_2019_600000` - > average precision, average recall"
   ],
   "metadata": {
    "id": "5pe2EpSRvm_e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "DyeHWOwm7eT1"
   },
   "outputs": [],
   "source": [
    "# Let's first load the last model, longer wait (few minutes)\n",
    "\n",
    "spell_config = read_speller_config('models/spell_etnc19_reference_corpus_6000000_web_2019_600000.yaml')\n",
    "speller = Speller(spell_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepearing input data\n",
    "\n",
    "From Str to Request."
   ],
   "metadata": {
    "id": "5tbPr16syA4I"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IHNv-0qp_2T_"
   },
   "outputs": [],
   "source": [
    "source_text = \"Ükss väega vikase lause olema see\"\n",
    "request = Request(text=source_text, language='et')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Spell-checking\n",
    "\n",
    "Only applying speller."
   ],
   "metadata": {
    "id": "0-Q8U6MJx6Yp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3VXw6Z4UggQ_",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "outputId": "f79c37cd-b413-4517-c952-55ebaf2c3a6f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'corrected_text': 'Üks väega vigase lause olema see',\n",
      " 'corrections': [{'replacements': [{'value': 'Üks'}],\n",
      "                  'span': {'end': 4, 'start': 0, 'value': 'Ükss'}},\n",
      "                 {'replacements': [{'value': 'vigase'}],\n",
      "                  'span': {'end': 17, 'start': 11, 'value': 'vikase'}}],\n",
      " 'original_text': 'Ükss väega vikase lause olema see',\n",
      " 'status': 'OK',\n",
      " 'status_code': 200}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Üks väega vigase lause olema see'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "response = speller.process_request(request)\n",
    "pprint(asdict(response))\n",
    "response.corrected_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grammatical error correction\n",
    "\n",
    "Only applying the GEC model."
   ],
   "metadata": {
    "id": "LHm1OHpayY2C"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sOie7rcGgXgL",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "outputId": "06c5d748-69d6-41b6-f0ff-fec7d9ea38ee"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'corrected_text': 'Üks vägeva vikase lause on see.',\n",
      " 'corrections': [{'replacements': [{'value': 'Üks vägeva'}],\n",
      "                  'span': {'end': 10, 'start': 0, 'value': 'Ükss väega'}},\n",
      "                 {'replacements': [{'value': 'on see.'}],\n",
      "                  'span': {'end': 33, 'start': 24, 'value': 'olema see'}}],\n",
      " 'original_text': 'Ükss väega vikase lause olema see',\n",
      " 'status': 'OK',\n",
      " 'status_code': 200}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Üks vägeva vikase lause on see.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "response = gec.process_request(request)\n",
    "pprint(asdict(response))\n",
    "response.corrected_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Spell-checking and GEC\n",
    "\n",
    "To determine the order in which the correctors are applied, create a model list using the MultipleCorrections class and then add the speller and GEC corrector to the list sequentially."
   ],
   "metadata": {
    "id": "BxohcCS8ysMr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ta3tn9SW7ksk"
   },
   "outputs": [],
   "source": [
    "multi_corrector = MultiCorrector()\n",
    "multi_corrector.add_corrector(speller)\n",
    "multi_corrector.add_corrector(gec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "IWq3RXgH7vJB",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "outputId": "17c979da-cf90-4cc1-b779-70d32547b920"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'corrected_text': 'Üks väga vigane lause on see.',\n",
      " 'corrections': [{'replacements': [{'value': 'Üks väga vigane'}],\n",
      "                  'span': {'end': 17,\n",
      "                           'start': 0,\n",
      "                           'value': 'Ükss väega vikase'}},\n",
      "                 {'replacements': [{'value': 'on see.'}],\n",
      "                  'span': {'end': 33, 'start': 24, 'value': 'olema see'}}],\n",
      " 'original_text': 'Ükss väega vikase lause olema see',\n",
      " 'status': 'OK',\n",
      " 'status_code': 200}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Üks väga vigane lause on see.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "response = multi_corrector.process_request(request)\n",
    "pprint(asdict(response))\n",
    "response.corrected_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparing the models\n",
    "\n",
    "There are two GEC and three spell-checking models that exhibit varying behaviors, here are some examples of that."
   ],
   "metadata": {
    "id": "vngfOkoBR9U9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Two GEC models\n",
    "\n",
    "The `GEC-noisy-nmt-ut` model exhibits higher error correction capability but is prone to confusion, while the `GEC-synthetic-pretrain-ut-ft` model is more stable but corrects fewer errors."
   ],
   "metadata": {
    "id": "BrahklQCzTRz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Mkd3qDFbifnz"
   },
   "outputs": [],
   "source": [
    "model_config_sp = read_gec_config('models/GEC-synthetic-pretrain-ut-ft.yaml')\n",
    "gec_sp = GEC(model_config_sp)\n",
    "\n",
    "model_config_nmt = read_gec_config('models/GEC-noisy-nmt-ut.yaml')\n",
    "gec_nmt = GEC(model_config_nmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "VuH4R4WbjUAW"
   },
   "outputs": [],
   "source": [
    "source_text_longer = \"Gramatikliste veade parantamine on põõnev ülessanne. Ükss väega vikase lause olema see. Mudel oskama selles ikka parandusi luua.\"\n",
    "request_longer = Request(text=source_text_longer, language='et')\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "response_sp = gec_sp.process_request(request_longer)\n",
    "#pprint(asdict(response_sp))\n",
    "response_sp.corrected_text\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "H80pVK900Rwg",
    "outputId": "1889bd72-2db5-4f4c-f484-22736c330a44"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Grammatiliste veade parandamine on põnev ülesanne. Üks väga vigane lause on see. Mudel oskab selles ikka parandusi luua.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "response_nmt = gec_nmt.process_request(request_longer)\n",
    "#pprint(asdict(response_nmt))\n",
    "response_nmt.corrected_text\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5pYflNUc0ZIq",
    "outputId": "cb4c521f-02a1-4cd0-af15-55b0046852a8"
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Grammatiliste vigade parandamine on põdev ülesseamine. Üks vägeva vikase lause on see. Mudel oskab selles ikka parandusi teha.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Three spellers\n",
    "\n",
    "The `etnc19_reference_corpus_model_6000000_lines`is able to find more spelling mistakes, but it is not always completely accurate. On the other hand, the `etnc19_web_2019` model allows more mistakes to remain in the text but makes fewer incorrect edits. The `etnc19_reference_corpus_6000000_web_2019_600000` model falls somewhere in between these two models."
   ],
   "metadata": {
    "id": "6DqnFkU83c6D"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "source_text_spell = \"Õikekiria veade parantamine on põnev ülessanne. Ükss väega vikane lause on see. Mudel osgab seda ikla parandada.\"\n",
    "request_spell = Request(text=source_text_spell, language='et')\n"
   ],
   "metadata": {
    "id": "FLJtNYvf4gCe"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# NB! the models are huge and Colab memory limited, monitor that\n",
    "\n",
    "speller_ref_web = speller # spelling.Spelling(\"etnc19_reference_corpus_6000000_web_2019_600000/etnc19_reference_corpus_6000000_web_2019_600000.bin\")\n",
    "response = speller_ref_web.process_request(request_spell)\n",
    "#pprint(asdict(response))\n",
    "response.corrected_text\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RHnetW2K4MUE",
    "outputId": "8bc4868a-f836-404e-f91a-8cf84f0e4036"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Õigekirja teade parandamine on põnev ülessanne. Üks väega vigane lause on see. Mudel oskab seda ikla parandada.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 28
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "speller_ref_config = read_speller_config('models/spell_etnc19_reference_corpus_model_6000000_lines.yaml')\n",
    "speller_ref = Speller(speller_ref_config)\n",
    "\n",
    "response = speller_ref.process_request(request_spell)\n",
    "#pprint(asdict(response))\n",
    "response.corrected_text\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "068w0Naj3hBM",
    "outputId": "10901def-68c0-45c8-9c60-4a6296856680"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Õigekirja teade parandamine on põnev ülesanne. Üks väega vigane lause on see. Mudel oskab seda ikla parandada.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 29
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "speller_web_config = read_speller_config('models/spell_etnc19_web_2019.yaml')\n",
    "speller_web = Speller(speller_web_config)\n",
    "\n",
    "response = speller_web.process_request(request_spell)\n",
    "#pprint(asdict(response))\n",
    "response.corrected_text\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "SdH4KsN84T88",
    "outputId": "621d6861-9260-421d-a7f9-d55785cc8086"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Õikekiria veade parantamine on põnev ülessanne. Ükss väega vikane lause on see. Mudel oskab seda ikka parandada.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 30
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
