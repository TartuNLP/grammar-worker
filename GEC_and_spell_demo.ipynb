{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TartuNLP/grammar-worker/blob/gec-and-spell/GEC_and_spell_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spell-checking and Grammatical Error Correction Demo\n",
        "\n",
        "Demo for using [https://koodivaramu.eesti.ee/tartunlp/corrector](https://koodivaramu.eesti.ee/tartunlp/corrector) that corrects Estonian text using spell-checking and grammatical error correction (GEC) models. "
      ],
      "metadata": {
        "id": "Jho_ZS1rtJwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Clone the repo, install dependencies and download models. It is advisable to create a Python 3.10 environment outside of Colab. "
      ],
      "metadata": {
        "id": "TfLyafy9tkvO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yRSNzEd5OWl",
        "outputId": "91282246-82d9-4a8b-c542-1e85187b8168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'grammar-worker'...\n",
            "remote: Enumerating objects: 359, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 359 (delta 58), reused 55 (delta 23), pack-reused 239\u001b[K\n",
            "Receiving objects: 100% (359/359), 108.96 KiB | 9.08 MiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n",
            "/content/grammar-worker\n",
            "Branch 'gec-and-spell' set up to track remote branch 'gec-and-spell' from 'origin'.\n",
            "Switched to a new branch 'gec-and-spell'\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig3.0\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 1,109 kB of archives.\n",
            "After this operation, 5,555 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 swig3.0 amd64 3.0.12-2.2ubuntu1 [1,109 kB]\n",
            "Fetched 1,109 kB in 0s (9,218 kB/s)\n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 122531 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-2.2ubuntu1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-2.2ubuntu1) ...\n",
            "Setting up swig3.0 (3.0.12-2.2ubuntu1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/TartuNLP/fairseq.git@mtee-0.1.0 (from -r requirements.txt (line 7))\n",
            "  Cloning https://github.com/TartuNLP/fairseq.git (to revision mtee-0.1.0) to /tmp/pip-req-build-v8zi8evz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/TartuNLP/fairseq.git /tmp/pip-req-build-v8zi8evz\n",
            "  Running command git checkout -q 1a6f364b8af6e746dd1fc623c8cf670a0be5b696\n",
            "  Resolved https://github.com/TartuNLP/fairseq.git to commit 1a6f364b8af6e746dd1fc623c8cf670a0be5b696\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  From https://github.com/ngoyal2707/Megatron-LM\n",
            "   * branch            adb23324c222aad0aad89308e70302d996a5eaeb -> FETCH_HEAD\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk~=3.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision==0.15.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.15.1+cu118)\n",
            "Requirement already satisfied: torchaudio==2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.0.1+cu118)\n",
            "Requirement already satisfied: pyyaml==6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (6.0)\n",
            "Collecting pika==1.3.1 (from -r requirements.txt (line 6))\n",
            "  Downloading pika-1.3.1-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.97 (from -r requirements.txt (line 8))\n",
            "  Downloading sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic~=1.10.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.10.7)\n",
            "Collecting fastapi~=0.95.0 (from -r requirements.txt (line 10))\n",
            "  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn~=0.21.1 (from -r requirements.txt (line 11))\n",
            "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.22.4)\n",
            "Collecting mosestokenizer==1.2.1 (from -r requirements.txt (line 13))\n",
            "  Downloading mosestokenizer-1.2.1.tar.gz (37 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub~=0.13.4 (from -r requirements.txt (line 14))\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stanza~=1.4.2 (from -r requirements.txt (line 15))\n",
            "  Downloading stanza-1.4.2-py3-none-any.whl (691 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.3/691.3 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jamspell~=0.0.12 (from -r requirements.txt (line 16))\n",
            "  Downloading jamspell-0.0.12.tar.gz (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1->-r requirements.txt (line 3)) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1->-r requirements.txt (line 3)) (8.4.0)\n",
            "Collecting docopt (from mosestokenizer==1.2.1->-r requirements.txt (line 13))\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openfile (from mosestokenizer==1.2.1->-r requirements.txt (line 13))\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting uctools (from mosestokenizer==1.2.1->-r requirements.txt (line 13))\n",
            "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting toolwrapper (from mosestokenizer==1.2.1->-r requirements.txt (line 13))\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 2)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 2)) (16.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (4.65.0)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (0.29.34)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7))\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7))\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7))\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitarray (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7))\n",
            "  Downloading bitarray-2.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.7/272.7 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi~=0.95.0->-r requirements.txt (line 10))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11>=0.8 (from uvicorn~=0.21.1->-r requirements.txt (line 11))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.13.4->-r requirements.txt (line 14)) (23.1)\n",
            "Collecting emoji (from stanza~=1.4.2->-r requirements.txt (line 15))\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanza~=1.4.2->-r requirements.txt (line 15)) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from stanza~=1.4.2->-r requirements.txt (line 15)) (1.16.0)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7))\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7))\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (0.8.10)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (4.9.2)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi~=0.95.0->-r requirements.txt (line 10)) (3.6.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->-r requirements.txt (line 2)) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 3)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 3)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 3)) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi~=0.95.0->-r requirements.txt (line 10)) (1.3.0)\n",
            "Building wheels for collected packages: mosestokenizer, fairseq, jamspell, antlr4-python3-runtime, docopt, emoji, toolwrapper, uctools\n",
            "  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mosestokenizer: filename=mosestokenizer-1.2.1-py3-none-any.whl size=49171 sha256=2e02e0edbb6e50702276494f2b6e8913c2facc4712ce63b7b19c42ea2d2a253b\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/d8/15/4c5ebbe883513f003cb055a0369c77c9df857023a706f39e70\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-1.0.0a0+1a6f364-cp310-cp310-linux_x86_64.whl size=3914651 sha256=53b4c1df1c5be02ed8cb180b5d5ce5c3c0efd2cc287f79ed8713c2f56939f750\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5zyt4heu/wheels/7e/e7/5e/576dd27c0aff762f3a5c556cd8a5e4b6dfe4ab8a8186275779\n",
            "  Building wheel for jamspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jamspell: filename=jamspell-0.0.12-cp310-cp310-linux_x86_64.whl size=1903661 sha256=1d50ab1218350ba4c5e3c0b661aa3b3002500e2f8835f702991e53e27eea948e\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/af/d3/fb57122fda2851ad5972ce80640001c568dcffdf16bc9ddb17\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=9f77652290caa574488ea582128637255b885708da91d6d903b4081c4a8a01c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=aecda778bfa1cf1132231b585b0ce2bdae37b76bb0a629d849a720485098f49d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234911 sha256=a1d436936965d82c9754c8b5ede61c56a179ab38486a102dcf6643dbca258e49\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/3d/88/51a592b9ad17e7899126563698b4e3961983ebe85747228ba6\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3337 sha256=0181e3a83d32b51610192bdc88a232ca2cae6cfdaecc24467759b65780fd860b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/af/b1/99b57a06dda78fdcee86d2e22c64743f3b8df8f31cfc04baf7\n",
            "  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6147 sha256=c73932b0b85f4219f0d80b3012f29fb37605f8dae3d51554140033af01b6e04e\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/ee/10/33257b0801ac6a912c841939032c16da1eb3db377afe1443e5\n",
            "Successfully built mosestokenizer fairseq jamspell antlr4-python3-runtime docopt emoji toolwrapper uctools\n",
            "Installing collected packages: toolwrapper, sentencepiece, openfile, jamspell, docopt, bitarray, antlr4-python3-runtime, uctools, portalocker, pika, omegaconf, h11, emoji, colorama, uvicorn, starlette, sacrebleu, mosestokenizer, hydra-core, huggingface-hub, fastapi, stanza, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.7.3 colorama-0.4.6 docopt-0.6.2 emoji-2.2.0 fairseq-1.0.0a0+1a6f364 fastapi-0.95.2 h11-0.14.0 huggingface-hub-0.13.4 hydra-core-1.0.7 jamspell-0.0.12 mosestokenizer-1.2.1 omegaconf-2.0.6 openfile-0.0.7 pika-1.3.1 portalocker-2.7.0 sacrebleu-2.3.1 sentencepiece-0.1.97 stanza-1.4.2 starlette-0.27.0 toolwrapper-2.1.0 uctools-1.3.0 uvicorn-0.21.1\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/TartuNLP/grammar-worker.git\n",
        "%cd grammar-worker\n",
        "! git checkout gec-and-spell\n",
        "! apt-get install swig3.0\n",
        "! pip install -r requirements.txt\n",
        "! python -c \"import nltk; nltk.download(\\\"punkt\\\")\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az5q9Jz27U3L",
        "outputId": "bf25d717-d7d6-45e1-b2b2-08403f61bc1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'models/tartuNLP/GEC-noisy-nmt-ut'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Total 19 (delta 0), reused 0 (delta 0), pack-reused 19\u001b[K\n",
            "Unpacking objects: 100% (19/19), 63.25 KiB | 6.32 MiB/s, done.\n",
            "Filtering content: 100% (3/3), 725.10 MiB | 31.82 MiB/s, done.\n",
            "Cloning into 'models/tartuNLP/GEC-synthetic-pretrain-ut-ft'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Unpacking objects: 100% (21/21), 63.46 KiB | 3.53 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 828.89 MiB | 33.40 MiB/s, done.\n",
            "Cloning into 'models/Jaagup/etnc19_reference_corpus_model_6000000_lines'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 12\u001b[K\n",
            "Unpacking objects: 100% (12/12), 1.39 KiB | 713.00 KiB/s, done.\n",
            "Cloning into 'models/Jaagup/etnc19_web_2019'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 6\u001b[K\n",
            "Unpacking objects: 100% (6/6), 815 bytes | 815.00 KiB/s, done.\n",
            "Cloning into 'models/Jaagup/etnc19_reference_corpus_6000000_web_2019_600000'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 3 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (6/6), 855 bytes | 855.00 KiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "! git lfs install\n",
        "\n",
        "# GEC models\n",
        "\n",
        "! git clone https://huggingface.co/tartuNLP/GEC-noisy-nmt-ut models/tartuNLP/GEC-noisy-nmt-ut\n",
        "! git clone https://huggingface.co/tartuNLP/GEC-synthetic-pretrain-ut-ft models/tartuNLP/GEC-synthetic-pretrain-ut-ft\n",
        "\n",
        "# Spell models\n",
        "\n",
        "! git clone https://huggingface.co/Jaagup/etnc19_reference_corpus_model_6000000_lines models/Jaagup/etnc19_reference_corpus_model_6000000_lines\n",
        "! git clone https://huggingface.co/Jaagup/etnc19_web_2019 models/Jaagup/etnc19_web_2019\n",
        "! git clone https://huggingface.co/Jaagup/etnc19_reference_corpus_6000000_web_2019_600000 models/Jaagup/etnc19_reference_corpus_6000000_web_2019_600000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models in action\n",
        "It is possible to use only speller or only GEC model or both models."
      ],
      "metadata": {
        "id": "QbZGDGhWvElx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yYqG3Yi45jPd"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "from dataclasses import asdict\n",
        "from gec_worker import GEC, read_gec_config\n",
        "from gec_worker import Speller, read_speller_config\n",
        "from gec_worker.dataclasses import Request\n",
        "from gec_worker import MultiCorrector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the models\n"
      ],
      "metadata": {
        "id": "iPNFtRwDxonZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two available GEC models are\n",
        "\n",
        "* `GEC-synthetic-pretrain-ut-ft` - > slightly higher precision & lower recall (preferred)\n",
        "* `GEC-noisy-nmt-ut` - > slightly higher recall & lower precision "
      ],
      "metadata": {
        "id": "WvcvXpiGvH2t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cOEDlt7I6ceg"
      },
      "outputs": [],
      "source": [
        "# Let's first load the second model\n",
        "\n",
        "gec_config = read_gec_config('models/GEC-noisy-nmt-ut.yaml')\n",
        "gec = GEC(gec_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three available spell-checking models are\n",
        "\n",
        "* `etnc19_reference_corpus_6000000` - > highest recall, lowest precision\n",
        "* `etnc19_web_2019` - > highest precision, lowest recall\n",
        "* `etnc19_reference_corpus_6000000_web_2019_600000` - > average precision, average recall"
      ],
      "metadata": {
        "id": "5pe2EpSRvm_e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DyeHWOwm7eT1"
      },
      "outputs": [],
      "source": [
        "# Let's first load the last model, longer wait (few minutes)\n",
        "\n",
        "spell_config = read_speller_config('models/spell_etnc19_reference_corpus_6000000_web_2019_600000.yaml')\n",
        "speller = Speller(spell_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepearing input data\n",
        "\n",
        "From Str to Request."
      ],
      "metadata": {
        "id": "5tbPr16syA4I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IHNv-0qp_2T_"
      },
      "outputs": [],
      "source": [
        "source_text = \"Ükss väega vikase lause olema see\"\n",
        "request = Request(text=source_text, language='et')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spell-checking\n",
        "\n",
        "Only applying speller."
      ],
      "metadata": {
        "id": "0-Q8U6MJx6Yp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3VXw6Z4UggQ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "33706fd1-26fd-4817-b228-61cca43db2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'corrected_text': 'Üks väega vigase lause olema see',\n",
            " 'corrections': [{'replacements': [{'value': 'Üks'}],\n",
            "                  'span': {'end': 4, 'start': 0, 'value': 'Ükss'}},\n",
            "                 {'replacements': [{'value': 'vigase'}],\n",
            "                  'span': {'end': 17, 'start': 11, 'value': 'vikase'}}],\n",
            " 'original_text': 'Ükss väega vikase lause olema see',\n",
            " 'status': 'OK',\n",
            " 'status_code': 200}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Üks väega vigase lause olema see'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "response = speller.process_request(request)\n",
        "pprint(asdict(response))\n",
        "response.corrected_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grammatical error correction\n",
        "\n",
        "Only applying the GEC model."
      ],
      "metadata": {
        "id": "LHm1OHpayY2C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sOie7rcGgXgL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "2ee4f8cc-d93f-4fcd-c62e-a0e3e3027429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'corrected_text': 'Üks vägeva vikase lause on see.',\n",
            " 'corrections': [{'replacements': [{'value': 'Üks vägeva'}],\n",
            "                  'span': {'end': 10, 'start': 0, 'value': 'Ükss väega'}},\n",
            "                 {'replacements': [{'value': 'on see.'}],\n",
            "                  'span': {'end': 33, 'start': 24, 'value': 'olema see'}}],\n",
            " 'original_text': 'Ükss väega vikase lause olema see',\n",
            " 'status': 'OK',\n",
            " 'status_code': 200}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Üks vägeva vikase lause on see.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "response = gec.process_request(request)\n",
        "pprint(asdict(response))\n",
        "response.corrected_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spell-checking and GEC\n",
        "\n",
        "To determine the order in which the correctors are applied, create a model list using the MultipleCorrections class and then add the speller and GEC corrector to the list sequentially."
      ],
      "metadata": {
        "id": "BxohcCS8ysMr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ta3tn9SW7ksk"
      },
      "outputs": [],
      "source": [
        "multi_corrector = MultiCorrector()\n",
        "multi_corrector.add_corrector(speller)\n",
        "multi_corrector.add_corrector(gec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IWq3RXgH7vJB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "2783eef0-5f2c-4698-c04d-827b3d96af55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'corrected_text': 'Üks väga vigane lause on see.',\n",
            " 'corrections': [{'replacements': [{'value': 'Üks väga vigane'}],\n",
            "                  'span': {'end': 17,\n",
            "                           'start': 0,\n",
            "                           'value': 'Ükss väega vikase'}},\n",
            "                 {'replacements': [{'value': 'on see.'}],\n",
            "                  'span': {'end': 33, 'start': 24, 'value': 'olema see'}}],\n",
            " 'original_text': 'Ükss väega vikase lause olema see',\n",
            " 'status': 'OK',\n",
            " 'status_code': 200}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Üks väga vigane lause on see.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "response = multi_corrector.process_request(request)\n",
        "pprint(asdict(response))\n",
        "response.corrected_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the models\n",
        "\n",
        "There are two GEC and three spell-checking models that exhibit varying behaviors, here are some examples of that."
      ],
      "metadata": {
        "id": "vngfOkoBR9U9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Two GEC models\n",
        "\n",
        "The `GEC-noisy-nmt-ut` model exhibits higher error correction capability but is prone to confusion, while the `GEC-synthetic-pretrain-ut-ft` model is more stable but corrects fewer errors."
      ],
      "metadata": {
        "id": "BrahklQCzTRz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Mkd3qDFbifnz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "4d8f295f8fad46b9af8ce3f682014377",
            "54765141b7424491934cac3a66921ad8",
            "66236933a9ca4d6f8e680fd36dd16471",
            "f437b7593a20442e8a082298a214ffc4",
            "299ba394741245e58b271e4be9900416",
            "99005041cce54bd3a2b0520c5a13b37b",
            "22e1b48f341f4851b4b786d6ad2bbb24",
            "e697430c41db4dbdae04404cc81fb5bd",
            "4581ce9b99be4521ab912a66e0a0c101",
            "068db9ff574b4a2e9320741d19a1eca4",
            "31150bcb0e2b4d71b3a2404e7bedd8a3",
            "2ad9ea38480e42dfa3457b3d24ebcbfb",
            "7d69fabce2694826891cbc3330122b09",
            "e9ff7e7dd67e414081044de8dd0b8cae",
            "2a55f1f1e15b4059909d36b58f1a3dbd",
            "6d482d569b4f425ebdcadbe482b49041",
            "542f4e457a8644a2b4f7eda09f2f18d6",
            "966deeaeb22447e58132c2114120db62",
            "a5d11c5999b040dab66f548a2e93d7d8",
            "0df4dec003194e1595518ef5e9a866a6",
            "38d19a899a794d9aa72179fc51fa7f7c",
            "b11a5bd798d04efeb6a02b43ea83ffc1"
          ]
        },
        "outputId": "d6f1a6bb-a705-41e8-fe11-08b5ba065892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d8f295f8fad46b9af8ce3f682014377"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-et/resolve/v1.4.1/models/tokenize/edt.pt:   0%|         …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ad9ea38480e42dfa3457b3d24ebcbfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Loading these models for language: et (Estonian):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | edt     |\n",
            "=======================\n",
            "\n",
            "INFO:stanza:Use device: gpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "model_config_sp = read_gec_config('models/GEC-synthetic-pretrain-ut-ft.yaml')\n",
        "gec_sp = GEC(model_config_sp)\n",
        "\n",
        "model_config_nmt = read_gec_config('models/GEC-noisy-nmt-ut.yaml')\n",
        "gec_nmt = GEC(model_config_nmt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VuH4R4WbjUAW"
      },
      "outputs": [],
      "source": [
        "source_text_longer = \"Gramatikliste veade parantamine on põõnev ülessanne. Ükss väega vikase lause olema see. Mudel oskama selles ikka parandusi luua.\"\n",
        "request_longer = Request(text=source_text_longer, language='et')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_sp = gec_sp.process_request(request_longer)\n",
        "#pprint(asdict(response_sp))\n",
        "response_sp.corrected_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "H80pVK900Rwg",
        "outputId": "1cc96cc5-58ec-4624-cc25-2a38b773deff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Grammatiliste veade parandamine on põnev ülesanne. Üks väga vigane lause on see. Mudel oskab selles ikka parandusi luua.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_nmt = gec_nmt.process_request(request_longer)\n",
        "#pprint(asdict(response_nmt))\n",
        "response_nmt.corrected_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5pYflNUc0ZIq",
        "outputId": "e95d633a-218a-4128-e7df-147016ebfc1a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Grammatiliste vigade parandamine on põdev ülesseamine. Üks vägeva vikase lause on see. Mudel oskab selles ikka parandusi teha.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Three spellers\n",
        "\n",
        "The `etnc19_reference_corpus_model_6000000_lines`is able to find more spelling mistakes, but it is not always completely accurate. On the other hand, the `etnc19_web_2019` model allows more mistakes to remain in the text but makes fewer incorrect edits. The `etnc19_reference_corpus_6000000_web_2019_600000` model falls somewhere in between these two models."
      ],
      "metadata": {
        "id": "6DqnFkU83c6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_text_spell = \"Õikekiria veade parantamine on põnev ülessanne. Ükss väega vikane lause on see. Mudel osgab seda ikla parandada.\"\n",
        "request_spell = Request(text=source_text_spell, language='et')\n"
      ],
      "metadata": {
        "id": "FLJtNYvf4gCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NB! the models are huge and Colab memory limited, monitor that\n",
        "\n",
        "speller_ref_web = speller # spelling.Spelling(\"etnc19_reference_corpus_6000000_web_2019_600000/etnc19_reference_corpus_6000000_web_2019_600000.bin\")\n",
        "response = speller_ref_web.process_request(request_spell)\n",
        "#pprint(asdict(response))\n",
        "response.corrected_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RHnetW2K4MUE",
        "outputId": "8bc4868a-f836-404e-f91a-8cf84f0e4036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Õigekirja teade parandamine on põnev ülessanne. Üks väega vigane lause on see. Mudel oskab seda ikla parandada.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speller_ref_config = read_speller_config('models/spell_etnc19_reference_corpus_model_6000000_lines.yaml')\n",
        "speller_ref = Speller(speller_ref_config)\n",
        "\n",
        "response = speller_ref.process_request(request_spell)\n",
        "#pprint(asdict(response))\n",
        "response.corrected_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "068w0Naj3hBM",
        "outputId": "10901def-68c0-45c8-9c60-4a6296856680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Õigekirja teade parandamine on põnev ülesanne. Üks väega vigane lause on see. Mudel oskab seda ikla parandada.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speller_web_config = read_speller_config('models/spell_etnc19_web_2019.yaml')\n",
        "speller_web = Speller(speller_web_config)\n",
        "\n",
        "response = speller_web.process_request(request_spell)\n",
        "#pprint(asdict(response))\n",
        "response.corrected_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SdH4KsN84T88",
        "outputId": "621d6861-9260-421d-a7f9-d55785cc8086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Õikekiria veade parantamine on põnev ülessanne. Ükss väega vikane lause on see. Mudel oskab seda ikka parandada.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d8f295f8fad46b9af8ce3f682014377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54765141b7424491934cac3a66921ad8",
              "IPY_MODEL_66236933a9ca4d6f8e680fd36dd16471",
              "IPY_MODEL_f437b7593a20442e8a082298a214ffc4"
            ],
            "layout": "IPY_MODEL_299ba394741245e58b271e4be9900416"
          }
        },
        "54765141b7424491934cac3a66921ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99005041cce54bd3a2b0520c5a13b37b",
            "placeholder": "​",
            "style": "IPY_MODEL_22e1b48f341f4851b4b786d6ad2bbb24",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: "
          }
        },
        "66236933a9ca4d6f8e680fd36dd16471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e697430c41db4dbdae04404cc81fb5bd",
            "max": 28918,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4581ce9b99be4521ab912a66e0a0c101",
            "value": 28918
          }
        },
        "f437b7593a20442e8a082298a214ffc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_068db9ff574b4a2e9320741d19a1eca4",
            "placeholder": "​",
            "style": "IPY_MODEL_31150bcb0e2b4d71b3a2404e7bedd8a3",
            "value": " 193k/? [00:00&lt;00:00, 10.6MB/s]"
          }
        },
        "299ba394741245e58b271e4be9900416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99005041cce54bd3a2b0520c5a13b37b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e1b48f341f4851b4b786d6ad2bbb24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e697430c41db4dbdae04404cc81fb5bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4581ce9b99be4521ab912a66e0a0c101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "068db9ff574b4a2e9320741d19a1eca4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31150bcb0e2b4d71b3a2404e7bedd8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ad9ea38480e42dfa3457b3d24ebcbfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d69fabce2694826891cbc3330122b09",
              "IPY_MODEL_e9ff7e7dd67e414081044de8dd0b8cae",
              "IPY_MODEL_2a55f1f1e15b4059909d36b58f1a3dbd"
            ],
            "layout": "IPY_MODEL_6d482d569b4f425ebdcadbe482b49041"
          }
        },
        "7d69fabce2694826891cbc3330122b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_542f4e457a8644a2b4f7eda09f2f18d6",
            "placeholder": "​",
            "style": "IPY_MODEL_966deeaeb22447e58132c2114120db62",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-et/resolve/v1.4.1/models/tokenize/edt.pt: 100%"
          }
        },
        "e9ff7e7dd67e414081044de8dd0b8cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5d11c5999b040dab66f548a2e93d7d8",
            "max": 635677,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0df4dec003194e1595518ef5e9a866a6",
            "value": 635677
          }
        },
        "2a55f1f1e15b4059909d36b58f1a3dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38d19a899a794d9aa72179fc51fa7f7c",
            "placeholder": "​",
            "style": "IPY_MODEL_b11a5bd798d04efeb6a02b43ea83ffc1",
            "value": " 636k/636k [00:00&lt;00:00, 17.9MB/s]"
          }
        },
        "6d482d569b4f425ebdcadbe482b49041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "542f4e457a8644a2b4f7eda09f2f18d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "966deeaeb22447e58132c2114120db62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5d11c5999b040dab66f548a2e93d7d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df4dec003194e1595518ef5e9a866a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38d19a899a794d9aa72179fc51fa7f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b11a5bd798d04efeb6a02b43ea83ffc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}