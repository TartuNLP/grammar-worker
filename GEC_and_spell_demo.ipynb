{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TartuNLP/grammar-worker/blob/main/GEC_and_spell_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jho_ZS1rtJwS"
      },
      "source": [
        "# Spell-checking and Grammatical Error Correction Demo\n",
        "\n",
        "Demo for using [https://koodivaramu.eesti.ee/tartunlp/corrector](https://koodivaramu.eesti.ee/tartunlp/corrector) that corrects Estonian text using spell-checking and grammatical error correction (GEC) models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfLyafy9tkvO"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Clone the repo, install dependencies and download models. It is advisable to create a Python 3.10 environment outside of Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yRSNzEd5OWl",
        "outputId": "e21e0ce6-3a83-4599-e22f-4c4aa5204f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'grammar-worker' already exists and is not an empty directory.\n",
            "/content/grammar-worker\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "swig3.0 is already the newest version (3.0.12-2.2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Collecting git+https://github.com/TartuNLP/fairseq.git@mtee-0.1.0 (from -r requirements.txt (line 7))\n",
            "  Cloning https://github.com/TartuNLP/fairseq.git (to revision mtee-0.1.0) to /tmp/pip-req-build-356kaow4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/TartuNLP/fairseq.git /tmp/pip-req-build-356kaow4\n",
            "  Running command git checkout -q 1a6f364b8af6e746dd1fc623c8cf670a0be5b696\n",
            "  Resolved https://github.com/TartuNLP/fairseq.git to commit 1a6f364b8af6e746dd1fc623c8cf670a0be5b696\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk~=3.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: torchvision==0.15.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.15.1)\n",
            "Requirement already satisfied: torchaudio==2.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.0.1)\n",
            "Requirement already satisfied: pyyaml==6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (6.0)\n",
            "Requirement already satisfied: pika==1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.97 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.1.97)\n",
            "Requirement already satisfied: pydantic~=1.10.7 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.10.14)\n",
            "Requirement already satisfied: fastapi~=0.95.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.95.2)\n",
            "Requirement already satisfied: uvicorn~=0.21.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.21.1)\n",
            "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.23.5)\n",
            "Requirement already satisfied: mosestokenizer==1.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.2.1)\n",
            "Requirement already satisfied: huggingface-hub~=0.13.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.13.4)\n",
            "Requirement already satisfied: stanza~=1.4.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (1.4.2)\n",
            "Requirement already satisfied: jamspell~=0.0.12 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1->-r requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1->-r requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from mosestokenizer==1.2.1->-r requirements.txt (line 13)) (0.6.2)\n",
            "Requirement already satisfied: openfile in /usr/local/lib/python3.10/dist-packages (from mosestokenizer==1.2.1->-r requirements.txt (line 13)) (0.0.7)\n",
            "Requirement already satisfied: uctools in /usr/local/lib/python3.10/dist-packages (from mosestokenizer==1.2.1->-r requirements.txt (line 13)) (1.3.0)\n",
            "Requirement already satisfied: toolwrapper in /usr/local/lib/python3.10/dist-packages (from mosestokenizer==1.2.1->-r requirements.txt (line 13)) (2.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 2)) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 2)) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 2)) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 2)) (17.0.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk~=3.7->-r requirements.txt (line 1)) (4.66.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (3.0.8)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (1.0.7)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (2.0.6)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (2.4.0)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (2.9.2)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi~=0.95.0->-r requirements.txt (line 10)) (0.27.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn~=0.21.1->-r requirements.txt (line 11)) (0.14.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.13.4->-r requirements.txt (line 14)) (23.2)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza~=1.4.2->-r requirements.txt (line 15)) (2.10.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanza~=1.4.2->-r requirements.txt (line 15)) (3.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from stanza~=1.4.2->-r requirements.txt (line 15)) (1.16.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (4.8)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (4.9.4)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi~=0.95.0->-r requirements.txt (line 10)) (3.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==1.0.0a0+1a6f364->-r requirements.txt (line 7)) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->-r requirements.txt (line 2)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi~=0.95.0->-r requirements.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi~=0.95.0->-r requirements.txt (line 10)) (1.2.0)\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `)'\n",
            "/bin/bash: -c: line 1: ` python -c 'import nltk; nltk.download(\\'punkt\\')''\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/TartuNLP/grammar-worker.git\n",
        "%cd grammar-worker\n",
        "! apt-get install swig3.0\n",
        "! pip install -r requirements.txt\n",
        "! python -c 'import nltk; nltk.download(\\'punkt\\')'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az5q9Jz27U3L",
        "outputId": "4bcd13a4-ae11-49ab-f783-751acab7837b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'models/tartuNLP/en-et-de-cs-nelb'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 38 (delta 11), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (38/38), 1.38 MiB | 8.19 MiB/s, done.\n",
            "Cloning into 'models/tartuNLP/GEC-noisy-nmt-ut'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Total 19 (delta 0), reused 0 (delta 0), pack-reused 19\u001b[K\n",
            "Unpacking objects: 100% (19/19), 63.25 KiB | 4.52 MiB/s, done.\n",
            "Cloning into 'models/tartuNLP/GEC-synthetic-pretrain-ut-ft'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21\u001b[K\n",
            "Unpacking objects: 100% (21/21), 63.46 KiB | 4.88 MiB/s, done.\n",
            "Filtering content: 100% (4/4), 828.89 MiB | 36.44 MiB/s, done.\n",
            "Cloning into 'models/Jaagup/etnc19_reference_corpus_model_6000000_lines'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 12\u001b[K\n",
            "Unpacking objects: 100% (12/12), 1.39 KiB | 356.00 KiB/s, done.\n",
            "Cloning into 'models/Jaagup/etnc19_web_2019'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 6\u001b[K\n",
            "Unpacking objects: 100% (6/6), 815 bytes | 407.00 KiB/s, done.\n",
            "Cloning into 'models/Jaagup/etnc19_reference_corpus_6000000_web_2019_600000'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 6\u001b[K\n",
            "Unpacking objects: 100% (6/6), 855 bytes | 213.00 KiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "! git lfs install\n",
        "\n",
        "# GEC models\n",
        "\n",
        "! git clone https://huggingface.co/tartuNLP/en-et-de-cs-nelb models/tartuNLP/en-et-de-cs-nelb\n",
        "! git clone https://huggingface.co/tartuNLP/GEC-noisy-nmt-ut models/tartuNLP/GEC-noisy-nmt-ut\n",
        "! git clone https://huggingface.co/tartuNLP/GEC-synthetic-pretrain-ut-ft models/tartuNLP/GEC-synthetic-pretrain-ut-ft\n",
        "\n",
        "# Spell models\n",
        "\n",
        "! git clone https://huggingface.co/Jaagup/etnc19_reference_corpus_model_6000000_lines models/Jaagup/etnc19_reference_corpus_model_6000000_lines\n",
        "! git clone https://huggingface.co/Jaagup/etnc19_web_2019 models/Jaagup/etnc19_web_2019\n",
        "! git clone https://huggingface.co/Jaagup/etnc19_reference_corpus_6000000_web_2019_600000 models/Jaagup/etnc19_reference_corpus_6000000_web_2019_600000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbZGDGhWvElx"
      },
      "source": [
        "## Models in action\n",
        "It is possible to use only speller or only GEC model or both models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYqG3Yi45jPd"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "from dataclasses import asdict\n",
        "from gec_worker import GEC, read_gec_config\n",
        "from gec_worker import Speller, read_speller_config\n",
        "from gec_worker.dataclasses import Request\n",
        "from gec_worker import MultiCorrector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPNFtRwDxonZ"
      },
      "source": [
        "### Loading the models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvcvXpiGvH2t"
      },
      "source": [
        "Three available GEC models are\n",
        "\n",
        "* `en-et-de-cs-nelb` - > second iteration model, both the highest precision & recall compared to the other ones (preferred)\n",
        "* `GEC-synthetic-pretrain-ut-ft` - > slightly higher precision & lower recall\n",
        "* `GEC-noisy-nmt-ut` - > slightly higher recall & lower precision\n",
        "\n",
        "**We suggest using the `en-et-de-cs-nelb` model.** It is a No Error Left Behind (NELB) model that is based on No Language Left Behing (NLLB) translation model. It has significantly better performance compared to the other ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOEDlt7I6ceg",
        "outputId": "cd3731b4-a540-429e-b4e1-e3ba0dc980dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fairseq.data.multilingual.multilingual_data_manager:External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n"
          ]
        }
      ],
      "source": [
        "# Let's load the highest-performing model\n",
        "\n",
        "gec_config = read_gec_config('models/GEC-nelb-1.3b.yaml')\n",
        "gec = GEC(gec_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pe2EpSRvm_e"
      },
      "source": [
        "Three available spell-checking models are\n",
        "\n",
        "* `etnc19_reference_corpus_6000000_lines` - > highest recall, lowest precision\n",
        "* `etnc19_web_2019` - > highest precision, lowest recall\n",
        "* `etnc19_reference_corpus_6000000_web_2019_600000` - > average precision, average recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyeHWOwm7eT1"
      },
      "outputs": [],
      "source": [
        "# Let's load the model with the highest recall\n",
        "\n",
        "spell_config = read_speller_config('models/spell_etnc19_reference_corpus_model_6000000_lines.yaml')\n",
        "speller = Speller(spell_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tbPr16syA4I"
      },
      "source": [
        "### Preparing input data\n",
        "\n",
        "From Str to Request."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHNv-0qp_2T_"
      },
      "outputs": [],
      "source": [
        "source_text = 'Ükss väega vikase lause olema see'\n",
        "#source_text = 'See onn üks väega viggane lause'\n",
        "request = Request(text=source_text, language='et')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-Q8U6MJx6Yp"
      },
      "source": [
        "### Spell-checking\n",
        "\n",
        "Only applying the speller."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VXw6Z4UggQ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "b86eea0c-262f-45dd-c940-5c213e277765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'corrected_text': 'See on üks väga vigane lause',\n",
            " 'corrections': [{'replacements': [{'value': 'on'}],\n",
            "                  'span': {'end': 7, 'start': 4, 'value': 'onn'}},\n",
            "                 {'replacements': [{'value': 'väga vigane'}],\n",
            "                  'span': {'end': 25, 'start': 12, 'value': 'väega viggane'}}],\n",
            " 'original_text': 'See onn üks väega viggane lause',\n",
            " 'status': 'OK',\n",
            " 'status_code': 200}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'See on üks väga vigane lause'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "response = speller.process_request(request)\n",
        "pprint(asdict(response))\n",
        "response.corrected_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHm1OHpayY2C"
      },
      "source": [
        "### Grammatical error correction\n",
        "\n",
        "Only applying the GEC model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOie7rcGgXgL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "9c779277-c921-49b2-fd97-afba45e0c7d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'corrected_text': 'Üks väga vigane lause on see.',\n",
            " 'corrections': [{'replacements': [{'value': 'Üks väga vigane'}],\n",
            "                  'span': {'end': 17,\n",
            "                           'start': 0,\n",
            "                           'value': 'Ükss väega vikase'}},\n",
            "                 {'replacements': [{'value': 'on see.'}],\n",
            "                  'span': {'end': 33, 'start': 24, 'value': 'olema see'}}],\n",
            " 'original_text': 'Ükss väega vikase lause olema see',\n",
            " 'status': 'OK',\n",
            " 'status_code': 200}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Üks väga vigane lause on see.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "response = gec.process_request(request)\n",
        "pprint(asdict(response))\n",
        "response.corrected_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxohcCS8ysMr"
      },
      "source": [
        "### Spell-checking and GEC\n",
        "\n",
        "To determine the order in which the correctors are applied, create a model list using the MultipleCorrections class and then add the speller and GEC corrector to the list sequentially."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta3tn9SW7ksk"
      },
      "outputs": [],
      "source": [
        "multi_corrector = MultiCorrector()\n",
        "multi_corrector.add_corrector(speller)\n",
        "multi_corrector.add_corrector(gec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWq3RXgH7vJB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "9c9128c0-71b7-41c2-892f-157d1bf56eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'corrected_text': 'Üks väga vigane lause on see.',\n",
            " 'corrections': [{'replacements': [{'value': 'Üks väga vigane'}],\n",
            "                  'span': {'end': 17,\n",
            "                           'start': 0,\n",
            "                           'value': 'Ükss väega vikase'}},\n",
            "                 {'replacements': [{'value': 'on see.'}],\n",
            "                  'span': {'end': 33, 'start': 24, 'value': 'olema see'}}],\n",
            " 'original_text': 'Ükss väega vikase lause olema see',\n",
            " 'status': 'OK',\n",
            " 'status_code': 200}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Üks väga vigane lause on see.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "response = multi_corrector.process_request(request)\n",
        "pprint(asdict(response))\n",
        "response.corrected_text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8dDMmPwrvhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vngfOkoBR9U9"
      },
      "source": [
        "## Comparing the models\n",
        "\n",
        "There are two GEC and three spell-checking models that exhibit varying behaviors, here are some examples of that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrahklQCzTRz"
      },
      "source": [
        "### Three GEC models\n",
        "\n",
        "The `GEC-noisy-nmt-ut` model exhibits higher error correction capability but is prone to confusion, while the `GEC-synthetic-pretrain-ut-ft` model is more stable but corrects fewer errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mkd3qDFbifnz"
      },
      "outputs": [],
      "source": [
        "gec_config_nelb = read_gec_config('models/GEC-nelb-1.3b.yaml')\n",
        "gec_nelb = GEC(gec_config_nelb)\n",
        "\n",
        "model_config_sp = read_gec_config('models/GEC-synthetic-pretrain-ut-ft.yaml')\n",
        "gec_sp = GEC(model_config_sp)\n",
        "\n",
        "model_config_nmt = read_gec_config('models/GEC-noisy-nmt-ut.yaml')\n",
        "gec_nmt = GEC(model_config_nmt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuH4R4WbjUAW"
      },
      "outputs": [],
      "source": [
        "source_text_longer = 'Gramatikliste veade parantamine on põõnev ülessanne. Ükss väega vikase lause olema see. Mudel oskama selles ikka parandusi teha.'\n",
        "request_longer = Request(text=source_text_longer, language='et')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H80pVK900Rwg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "267e69e3-fc4c-425a-e625-337f35a1ce9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Grammatiliste veade parandamine on põnev ülesanne. Üks väga vigane lause on see. Mudel oskab selles ikka parandusi teha.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "response_sp = gec_sp.process_request(request_longer)\n",
        "#pprint(asdict(response_sp))\n",
        "response_sp.corrected_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pYflNUc0ZIq"
      },
      "outputs": [],
      "source": [
        "response_nmt = gec_nmt.process_request(request_longer)\n",
        "#pprint(asdict(response_nmt))\n",
        "response_nmt.corrected_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN7HngJ9JxlL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8fc7b387-edb6-4404-a2a5-bbb9fd4491c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Grammatiliste vigade parandamine on põnev ülesanne. Üks väga vigane lause on see. Mudel oskab selles ikka parandusi teha.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "response_nelb = gec_nelb.process_request(request_longer)\n",
        "#pprint(asdict(response_nmt))\n",
        "response_nelb.corrected_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DqnFkU83c6D"
      },
      "source": [
        "### Three spellers\n",
        "\n",
        "The `etnc19_reference_corpus_model_6000000_lines`is able to find more spelling mistakes, but it is not always completely accurate. On the other hand, the `etnc19_web_2019` model allows more mistakes to remain in the text but makes fewer incorrect edits. The `etnc19_reference_corpus_6000000_web_2019_600000` model falls somewhere in between these two models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLJtNYvf4gCe"
      },
      "outputs": [],
      "source": [
        "source_text_spell = 'Õikekiria veade parantamine on põnev ülessanne. Ükss väega vikane lause on see. Mudel osgab seda ikla parandada.'\n",
        "request_spell = Request(text=source_text_spell, language='et')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RHnetW2K4MUE",
        "outputId": "8bc4868a-f836-404e-f91a-8cf84f0e4036"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Õigekirja teade parandamine on põnev ülessanne. Üks väega vigane lause on see. Mudel oskab seda ikla parandada.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NB! the models are huge and Colab memory limited, monitor that\n",
        "\n",
        "speller_ref_web = speller # spelling.Spelling(\"etnc19_reference_corpus_6000000_web_2019_600000/etnc19_reference_corpus_6000000_web_2019_600000.bin\")\n",
        "response = speller_ref_web.process_request(request_spell)\n",
        "#pprint(asdict(response))\n",
        "response.corrected_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "068w0Naj3hBM",
        "outputId": "10901def-68c0-45c8-9c60-4a6296856680"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Õigekirja teade parandamine on põnev ülesanne. Üks väega vigane lause on see. Mudel oskab seda ikla parandada.'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "speller_ref_config = read_speller_config('models/spell_etnc19_reference_corpus_model_6000000_lines.yaml')\n",
        "speller_ref = Speller(speller_ref_config)\n",
        "\n",
        "response = speller_ref.process_request(request_spell)\n",
        "#pprint(asdict(response))\n",
        "response.corrected_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SdH4KsN84T88",
        "outputId": "621d6861-9260-421d-a7f9-d55785cc8086"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Õikekiria veade parantamine on põnev ülessanne. Ükss väega vikane lause on see. Mudel oskab seda ikka parandada.'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "speller_web_config = read_speller_config('models/spell_etnc19_web_2019.yaml')\n",
        "speller_web = Speller(speller_web_config)\n",
        "\n",
        "response = speller_web.process_request(request_spell)\n",
        "#pprint(asdict(response))\n",
        "response.corrected_text\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}